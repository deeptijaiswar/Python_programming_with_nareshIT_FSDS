{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e4419b-ddb3-42e0-85e8-9ba4243e5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diffusers\n",
      "  Downloading diffusers-0.33.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from diffusers) (7.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from diffusers) (3.13.1)\n",
      "Collecting huggingface-hub>=0.27.0 (from diffusers)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from diffusers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from diffusers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from diffusers) (2.32.3)\n",
      "Collecting safetensors>=0.3.1 (from diffusers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from diffusers) (10.4.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.27.0->diffusers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.27.0->diffusers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.27.0->diffusers) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.27.0->diffusers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.27.0->diffusers) (4.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from importlib-metadata->diffusers) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from requests->diffusers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from requests->diffusers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from requests->diffusers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from requests->diffusers) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.27.0->diffusers) (0.4.6)\n",
      "Downloading diffusers-0.33.1-py3-none-any.whl (3.6 MB)\n",
      "   ---------------------------------------- 0.0/3.6 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 2.6/3.6 MB 13.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.6/3.6 MB 11.7 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Installing collected packages: safetensors, huggingface-hub, diffusers\n",
      "Successfully installed diffusers-0.33.1 huggingface-hub-0.30.2 safetensors-0.5.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install diffusers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e5811c3-4cd4-4d62-b1fb-ba65c8200b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting invisible_watermark\n",
      "  Downloading invisible_watermark-0.2.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: safetensors in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (0.5.3)\n",
      "Requirement already satisfied: Pillow>=6.0.0 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from invisible_watermark) (10.4.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from invisible_watermark) (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from invisible_watermark) (1.26.4)\n",
      "Collecting opencv-python>=4.1.0.25 (from invisible_watermark)\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting torch (from invisible_watermark)\n",
      "  Downloading torch-2.6.0-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from torch->invisible_watermark) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from torch->invisible_watermark) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from torch->invisible_watermark) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch->invisible_watermark)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch->invisible_watermark) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from jinja2->torch->invisible_watermark) (2.1.3)\n",
      "Downloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 14.7 MB/s eta 0:00:00\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "   ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 3.1/10.4 MB 14.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.0/10.4 MB 14.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.4/10.4 MB 15.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.4/10.4 MB 12.2 MB/s eta 0:00:00\n",
      "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "   ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.6/39.5 MB 7.0 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 3.7/39.5 MB 8.7 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 6.8/39.5 MB 11.0 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 8.9/39.5 MB 12.0 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 12.6/39.5 MB 12.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 16.5/39.5 MB 13.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 20.4/39.5 MB 14.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 24.6/39.5 MB 14.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 27.3/39.5 MB 14.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 31.2/39.5 MB 15.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.9/39.5 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/39.5 MB 15.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.5/39.5 MB 15.0 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -------------------------------------- - 2.4/2.4 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 9.9 MB/s eta 0:00:00\n",
      "Downloading torch-2.6.0-cp312-cp312-win_amd64.whl (204.1 MB)\n",
      "   ---------------------------------------- 0.0/204.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 3.4/204.1 MB 18.3 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 6.8/204.1 MB 17.5 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 11.0/204.1 MB 18.1 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 14.7/204.1 MB 18.1 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 17.6/204.1 MB 17.0 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 19.9/204.1 MB 16.8 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 24.1/204.1 MB 16.4 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 28.0/204.1 MB 16.9 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 31.5/204.1 MB 16.9 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 33.0/204.1 MB 15.9 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 37.0/204.1 MB 16.2 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 40.6/204.1 MB 16.4 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 44.6/204.1 MB 16.6 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 46.9/204.1 MB 16.5 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 50.6/204.1 MB 16.2 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 54.3/204.1 MB 16.3 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 57.1/204.1 MB 16.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 59.8/204.1 MB 15.9 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 62.4/204.1 MB 15.8 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 66.1/204.1 MB 15.9 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 70.0/204.1 MB 16.0 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 73.9/204.1 MB 16.1 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 77.1/204.1 MB 16.1 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 79.7/204.1 MB 15.9 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 83.4/204.1 MB 16.0 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 87.3/204.1 MB 16.1 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 91.2/204.1 MB 16.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 95.2/204.1 MB 16.3 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 98.0/204.1 MB 16.2 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 102.0/204.1 MB 16.3 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 105.9/204.1 MB 16.4 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 109.8/204.1 MB 16.5 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 113.8/204.1 MB 16.6 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 116.4/204.1 MB 16.4 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 119.8/204.1 MB 16.4 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 123.7/204.1 MB 16.5 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 127.4/204.1 MB 16.6 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 130.5/204.1 MB 16.6 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 134.0/204.1 MB 16.5 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 137.6/204.1 MB 16.5 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 141.8/204.1 MB 16.6 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 145.5/204.1 MB 16.6 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 148.1/204.1 MB 16.5 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 151.8/204.1 MB 16.5 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 155.5/204.1 MB 16.6 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 159.1/204.1 MB 16.6 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 163.8/204.1 MB 16.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 167.5/204.1 MB 16.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 171.2/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 176.4/204.1 MB 16.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 181.1/204.1 MB 17.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 185.9/204.1 MB 17.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 188.2/204.1 MB 17.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 192.7/204.1 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 195.8/204.1 MB 17.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.5/204.1 MB 17.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.4/204.1 MB 17.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.1 MB 17.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 204.1/204.1 MB 16.8 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 3.1/6.2 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 15.8 MB/s eta 0:00:00\n",
      "Installing collected packages: sympy, opencv-python, torch, tokenizers, invisible_watermark, accelerate, transformers\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed accelerate-1.6.0 invisible_watermark-0.2.0 opencv-python-4.11.0.86 sympy-1.13.1 tokenizers-0.21.1 torch-2.6.0 transformers-4.51.3\n"
     ]
    }
   ],
   "source": [
    "!pip install invisible_watermark transformers accelerate safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2bed0df-008a-4dbb-9f8b-4b115cea541b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f0e8b362134fbd9bf580a7f3eb439e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m pipe \u001b[38;5;241m=\u001b[39m DiffusionPipeline\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstabilityai/stable-diffusion-xl-base-1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16, use_safetensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, variant\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m pipe\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# if using torch < 2.0\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# pipe.enable_xformers_memory_efficient_attention()\u001b[39;00m\n\u001b[0;32m     10\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn astronaut riding a green horse\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\diffusers\\pipelines\\pipeline_utils.py:482\u001b[0m, in \u001b[0;36mDiffusionPipeline.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    480\u001b[0m     module\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_loaded_in_4bit_bnb \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_loaded_in_8bit_bnb \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_group_offloaded:\n\u001b[1;32m--> 482\u001b[0m     module\u001b[38;5;241m.\u001b[39mto(device, dtype)\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    485\u001b[0m     module\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(device) \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silence_dtype_warnings\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_offloaded\n\u001b[0;32m    489\u001b[0m ):\n\u001b[0;32m    490\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    492\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not recommended to move them to `cpu` as running them will fail. Please make\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `torch_dtype=torch.float16` argument, or use another device for inference.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    496\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:3698\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[0;32m   3694\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3695\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3696\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3697\u001b[0m         )\n\u001b[1;32m-> 3698\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1343\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1340\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1341\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 903\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 903\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 903\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 930\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[0;32m    931\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    933\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1329\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1324\u001b[0m             device,\n\u001b[0;32m   1325\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1326\u001b[0m             non_blocking,\n\u001b[0;32m   1327\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1328\u001b[0m         )\n\u001b[1;32m-> 1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1330\u001b[0m         device,\n\u001b[0;32m   1331\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1332\u001b[0m         non_blocking,\n\u001b[0;32m   1333\u001b[0m     )\n\u001b[0;32m   1334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "# if using torch < 2.0\n",
    "# pipe.enable_xformers_memory_efficient_attention()\n",
    "\n",
    "prompt = \"An astronaut riding a green horse\"\n",
    "\n",
    "images = pipe(prompt=prompt).images[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bcad925-a6d5-4eca-93a7-d2526b4b21fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "517a8a90-9fd8-4a92-926f-d4ccd8fbe4f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nvcc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nvcc \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m-\u001b[39mversion\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nvcc' is not defined"
     ]
    }
   ],
   "source": [
    "nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b65f5a8e-e859-4f79-90ff-d7b3b56028bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.15.0-cp312-cp312-win_amd64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\deepti jaiswar\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "   ---------------------------------------- 0.0/376.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/376.0 MB 8.5 MB/s eta 0:00:45\n",
      "   ---------------------------------------- 1.0/376.0 MB 3.1 MB/s eta 0:02:00\n",
      "   ---------------------------------------- 3.7/376.0 MB 5.9 MB/s eta 0:01:04\n",
      "    --------------------------------------- 8.7/376.0 MB 10.7 MB/s eta 0:00:35\n",
      "   - -------------------------------------- 13.9/376.0 MB 13.8 MB/s eta 0:00:27\n",
      "   -- ------------------------------------- 18.9/376.0 MB 15.7 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 20.7/376.0 MB 16.2 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 24.1/376.0 MB 14.8 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 29.6/376.0 MB 16.1 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 33.8/376.0 MB 16.5 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 39.1/376.0 MB 17.2 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 41.7/376.0 MB 16.9 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 46.1/376.0 MB 17.3 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 51.1/376.0 MB 17.8 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 55.1/376.0 MB 17.8 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 59.5/376.0 MB 18.1 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 61.3/376.0 MB 17.5 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 65.5/376.0 MB 17.6 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 70.3/376.0 MB 17.9 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 75.2/376.0 MB 18.2 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 78.6/376.0 MB 18.3 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 82.3/376.0 MB 18.0 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 87.3/376.0 MB 18.3 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 92.0/376.0 MB 18.5 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 96.5/376.0 MB 18.7 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 99.6/376.0 MB 18.5 MB/s eta 0:00:15\n",
      "   ---------- ---------------------------- 104.1/376.0 MB 18.6 MB/s eta 0:00:15\n",
      "   ----------- --------------------------- 109.3/376.0 MB 18.8 MB/s eta 0:00:15\n",
      "   ----------- --------------------------- 114.3/376.0 MB 19.0 MB/s eta 0:00:14\n",
      "   ------------ -------------------------- 119.3/376.0 MB 19.2 MB/s eta 0:00:14\n",
      "   ------------ -------------------------- 122.2/376.0 MB 19.0 MB/s eta 0:00:14\n",
      "   ------------- ------------------------- 126.9/376.0 MB 19.2 MB/s eta 0:00:14\n",
      "   ------------- ------------------------- 131.9/376.0 MB 19.3 MB/s eta 0:00:13\n",
      "   -------------- ------------------------ 135.8/376.0 MB 19.3 MB/s eta 0:00:13\n",
      "   -------------- ------------------------ 140.0/376.0 MB 19.3 MB/s eta 0:00:13\n",
      "   -------------- ------------------------ 142.1/376.0 MB 19.1 MB/s eta 0:00:13\n",
      "   --------------- ----------------------- 147.6/376.0 MB 19.3 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 151.8/376.0 MB 19.3 MB/s eta 0:00:12\n",
      "   ---------------- ---------------------- 156.8/376.0 MB 19.4 MB/s eta 0:00:12\n",
      "   ---------------- ---------------------- 161.7/376.0 MB 19.5 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 164.6/376.0 MB 19.4 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 169.1/376.0 MB 19.5 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 172.8/376.0 MB 19.4 MB/s eta 0:00:11\n",
      "   ------------------ -------------------- 176.7/376.0 MB 19.4 MB/s eta 0:00:11\n",
      "   ------------------ -------------------- 180.4/376.0 MB 19.3 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 183.2/376.0 MB 19.2 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 187.7/376.0 MB 19.3 MB/s eta 0:00:10\n",
      "   ------------------- ------------------- 192.4/376.0 MB 19.3 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 196.6/376.0 MB 19.3 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 200.0/376.0 MB 19.4 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 203.7/376.0 MB 19.2 MB/s eta 0:00:09\n",
      "   --------------------- ----------------- 208.9/376.0 MB 19.4 MB/s eta 0:00:09\n",
      "   --------------------- ----------------- 211.3/376.0 MB 19.3 MB/s eta 0:00:09\n",
      "   ---------------------- ---------------- 216.0/376.0 MB 19.3 MB/s eta 0:00:09\n",
      "   ---------------------- ---------------- 218.9/376.0 MB 19.3 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 222.3/376.0 MB 19.1 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 226.8/376.0 MB 19.2 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 231.2/376.0 MB 19.2 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 235.4/376.0 MB 19.2 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 237.8/376.0 MB 19.1 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 242.2/376.0 MB 19.1 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 246.7/376.0 MB 19.1 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 249.8/376.0 MB 19.1 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 253.2/376.0 MB 19.0 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 256.4/376.0 MB 18.9 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 260.6/376.0 MB 19.0 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 264.8/376.0 MB 19.6 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 269.5/376.0 MB 19.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 273.7/376.0 MB 19.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 277.1/376.0 MB 19.4 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 281.3/376.0 MB 19.3 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 286.3/376.0 MB 19.6 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 291.2/376.0 MB 19.6 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 293.3/376.0 MB 19.5 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 297.3/376.0 MB 19.4 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 301.7/376.0 MB 19.3 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 305.9/376.0 MB 19.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 310.1/376.0 MB 19.4 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 313.0/376.0 MB 19.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 317.5/376.0 MB 19.3 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 322.7/376.0 MB 19.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 326.1/376.0 MB 19.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 330.0/376.0 MB 19.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 333.4/376.0 MB 19.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 337.9/376.0 MB 19.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 341.8/376.0 MB 19.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 346.6/376.0 MB 19.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 351.8/376.0 MB 19.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 354.7/376.0 MB 19.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 359.7/376.0 MB 19.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 364.1/376.0 MB 19.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  369.1/376.0 MB 19.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  373.0/376.0 MB 19.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 376.0/376.0 MB 18.6 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 3.7/4.3 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 12.9 MB/s eta 0:00:00\n",
      "Downloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 17.1 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 4.2/26.4 MB 19.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 8.1/26.4 MB 19.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 12.1/26.4 MB 19.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 13.6/26.4 MB 19.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 16.8/26.4 MB 16.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.2/26.4 MB 17.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.7/26.4 MB 17.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 17.1 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 2.1/5.5 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 14.6 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp312-cp312-win_amd64.whl (307 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.2.2 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 keras-3.9.2 libclang-18.1.1 ml-dtypes-0.5.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.15.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d82c309c-ecce-4a4d-a999-07dd00ecd257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de433246-2770-4924-bc54-a6aa3582e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a57beb11-37e9-4067-8b36-11192b9ec4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to detect a GPU.\n"
     ]
    }
   ],
   "source": [
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(\"Found a GPU with the name:\", gpu)\n",
    "else:\n",
    "    print(\"Failed to detect a GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03ab15d9-21cc-4562-b24f-a81976078ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f25e1ef-b135-4010-8554-a5a8c8c5e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f645894a-29fb-415b-8a31-dd2e44ff9544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f95118e3b14ffaa9d3da6de90e02b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m pipe \u001b[38;5;241m=\u001b[39m DiffusionPipeline\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstabilityai/stable-diffusion-xl-base-1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16, use_safetensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, variant\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m pipe\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\diffusers\\pipelines\\pipeline_utils.py:482\u001b[0m, in \u001b[0;36mDiffusionPipeline.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    480\u001b[0m     module\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_loaded_in_4bit_bnb \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_loaded_in_8bit_bnb \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_group_offloaded:\n\u001b[1;32m--> 482\u001b[0m     module\u001b[38;5;241m.\u001b[39mto(device, dtype)\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    485\u001b[0m     module\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(device) \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silence_dtype_warnings\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_offloaded\n\u001b[0;32m    489\u001b[0m ):\n\u001b[0;32m    490\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    492\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not recommended to move them to `cpu` as running them will fail. Please make\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `torch_dtype=torch.float16` argument, or use another device for inference.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    496\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:3698\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[0;32m   3694\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3695\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3696\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3697\u001b[0m         )\n\u001b[1;32m-> 3698\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1343\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1340\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1341\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 903\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 903\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 903\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 930\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[0;32m    931\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    933\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1329\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1324\u001b[0m             device,\n\u001b[0;32m   1325\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1326\u001b[0m             non_blocking,\n\u001b[0;32m   1327\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1328\u001b[0m         )\n\u001b[1;32m-> 1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1330\u001b[0m         device,\n\u001b[0;32m   1331\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1332\u001b[0m         non_blocking,\n\u001b[0;32m   1333\u001b[0m     )\n\u001b[0;32m   1334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
    "pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d51c35d-2c21-411f-89bd-8db1317ac190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

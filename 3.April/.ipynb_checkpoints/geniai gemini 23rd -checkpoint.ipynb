{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaec964f-2306-49c0-9b20-8dd31076a81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Deepti Jaiswar\\anaconda3\\Lib\\site-packages\\google\\~rotobuf'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfc3b3df-e7c2-4a0f-b735-d53fa3e8c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62753799-d4c8-4547-ad63-77d0fc5997d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key='AIzaSyDzqJI0mIvO-75CSTSWClq-syb93YgrDPg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43f01a10-6759-4d16-a3e1-659c1e9e857c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down \"model context protocol\" using simple ideas, like talking to a friend!\n",
      "\n",
      "Imagine I'm a super smart computer program (that's the **Model**).\n",
      "\n",
      "When we talk, you don't just say one sentence and stop. You have a conversation, right? You build on what you said before.\n",
      "\n",
      "1.  **Context:** Think of **Context** like remembering the story of our conversation. If you say, \"It was really cool!\" I need to remember *what* was cool to understand you. Was it a movie? A game? Your school project? The conversation we had *just before* is the context.\n",
      "\n",
      "2.  **Protocol:** Now, the **Protocol** is just the *system* or the *rules* I use to manage that memory (the context). It's how I decide:\n",
      "    *   What parts of our conversation are important to remember?\n",
      "    *   How much of the conversation can I remember? (Like, I can't remember *everything* we've ever talked about since the beginning of time!)\n",
      "    *   How do I use that memory to understand what you're saying *now* and give you a good answer?\n",
      "\n",
      "**Think of it like having a limited notebook or scratchpad:**\n",
      "\n",
      "*   As we talk, I quickly write down the most important points from our recent conversation in my notebook (that's the **Context**).\n",
      "*   The way I decide what to write down and how to use those notes is my **Protocol**.\n",
      "\n",
      "**Why is this important?**\n",
      "\n",
      "Without this system (the protocol for handling context), I would forget what we were talking about almost instantly. If you asked, \"What about that?\" I wouldn't know what \"that\" refers to!\n",
      "\n",
      "The **Model Context Protocol** is just the smart way the computer program (the model) manages and uses the recent conversation history (the context) so it can understand you and keep talking in a helpful, sensible way, kind of like you remember what your friend just said during a chat.\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-2.5-flash-preview-04-17\")\n",
    "\n",
    "response = model.generate_content(\"what is model context prtocol can you explain to school student\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d196cd72-f540-49df-9616-b37b47bd2bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

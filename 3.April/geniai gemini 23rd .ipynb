{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaec964f-2306-49c0-9b20-8dd31076a81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Deepti Jaiswar\\anaconda3\\Lib\\site-packages\\google\\~rotobuf'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfc3b3df-e7c2-4a0f-b735-d53fa3e8c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62753799-d4c8-4547-ad63-77d0fc5997d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key='AIzaSyDzqJI0mIvO-75CSTSWClq-syb93YgrDPg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6716cee-e51d-41d2-b367-13bd6ab35e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, imagine you're talking to a friend. When you ask them a question, they don't just listen to *that one question*. They also remember:\n",
      "\n",
      "1.  **What you just talked about:** The conversation you've been having right now.\n",
      "2.  **Maybe some things you talked about before:** Especially if it's related.\n",
      "3.  **The situation you're in:** Are you at school? Playing a game? This background helps them understand your question better.\n",
      "\n",
      "This background information – everything *around* the current question – is called **context**.\n",
      "\n",
      "Now, think about an AI model, like the one you're talking to right now. It's like your friend, but a computer program. It also needs context to understand you properly and give good answers.\n",
      "\n",
      "Here's where \"Model Context Protocol\" comes in:\n",
      "\n",
      "*   **Model:** That's the AI program itself (like me!).\n",
      "*   **Context:** That's the background information – usually, it's the history of our conversation.\n",
      "*   **Protocol:** This is like a set of **rules** or a **system** for *how* the computer gives the AI model the context.\n",
      "\n",
      "So, the **Model Context Protocol** is simply the **rules and methods that the computer system uses to give the AI model the necessary background information (like our conversation history) so the AI can understand your current message and respond correctly.**\n",
      "\n",
      "**Think of it like this:**\n",
      "\n",
      "When you send a message to the AI, the system doesn't *just* send your new message. The protocol tells the system to *also* package up some of the recent conversation and send it along with your new message.\n",
      "\n",
      "**Why is this important?**\n",
      "\n",
      "*   **Without context:** If the AI forgot everything after every message, you'd have to explain everything again each time! Like asking \"What do you think?\" and the AI having no idea you were just talking about a movie.\n",
      "*   **With context (managed by the protocol):** The AI can remember what we were discussing. If you ask a follow-up question like \"Tell me more about that,\" the AI knows what \"that\" refers to because the context (the previous messages) was provided according to the protocol.\n",
      "\n",
      "**In simple terms:** The Model Context Protocol is the system's way of making sure the AI has a short-term \"memory\" of your conversation so it can understand you better and talk to you like you're having a real chat, not just sending one-off questions. It's the rules for *how* that conversation memory is given to the AI.\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-2.5-flash-preview-04-17\")\n",
    "\n",
    "response = model.generate_content(\"what is model context prtocol can you explain to school student\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43f01a10-6759-4d16-a3e1-659c1e9e857c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you're playing a guessing game. I'm thinking of a number, and you have to guess it. \n",
      "\n",
      "*   **Without context:** If I just say, \"Guess a number!\", you'd be completely lost! It could be *any* number in the whole universe.\n",
      "\n",
      "*   **With context:** Now, let's say I tell you, \"I'm thinking of a number between 1 and 10.\"  That's **context**! It narrows down the possibilities and helps you make a better guess.\n",
      "\n",
      "**Model Context Protocol (MCP) is like giving a computer (or a robot) the right context so it can do a better job.**\n",
      "\n",
      "Think of it this way:\n",
      "\n",
      "*   **The \"Model\":** This is the computer program or AI, like a chatbot, image generator, or even a self-driving car. It needs information to make decisions.\n",
      "*   **The \"Context\":** This is the extra information you give the model to help it understand what you want or what it should do.  It's like explaining the rules of the game before you start playing.\n",
      "*   **The \"Protocol\":** This is the set of rules or guidelines for *how* you give the context to the model so it understands it correctly.\n",
      "\n",
      "**Examples:**\n",
      "\n",
      "1.  **Chatbot:** If you ask a chatbot \"What's the capital?\", it needs context.  If you say \"What's the capital of *France*?\", you've provided the context!  MCP would be how you make sure the chatbot understands you're asking about a country's capital, not something else.\n",
      "\n",
      "2.  **Image Generator:**  If you tell an image generator \"Draw a cat,\" it might draw any kind of cat. But if you say \"Draw a *cartoon* cat, wearing a *hat*, in the *style of Picasso*,\" you're giving it more context, leading to a more specific and (hopefully) better image. MCP makes sure the generator knows exactly what each part of your request means (cartoon, hat, Picasso).\n",
      "\n",
      "3.  **Self-Driving Car:** A self-driving car needs to know the context of its surroundings: where it is, what the traffic laws are, where the pedestrians are, what the road conditions are. MCP helps make sure the car interprets all that information correctly so it can drive safely.\n",
      "\n",
      "**Why is MCP important?**\n",
      "\n",
      "*   **Accuracy:**  Giving the model clear context helps it give the correct answer or make the right decision.\n",
      "*   **Efficiency:**  It saves time and effort because the model doesn't have to guess what you mean.\n",
      "*   **Control:**  It gives you more control over what the model does.\n",
      "*   **Safety:**  In situations like self-driving cars, good context is crucial for safety.\n",
      "\n",
      "**In short, Model Context Protocol is a way of making sure computers get the information they need to do their jobs well. It's like giving them the right instructions and background information before they start.**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "response = model.generate_content(\"what is model context prtocol can you explain to school student\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d196cd72-f540-49df-9616-b37b47bd2bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
